{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 最常见的 CNNs架构\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/CNNs%E6%9E%B6%E6%9E%84.png)\n",
    "\n",
    "## 2. 使用Keras建立你的第一个CNNs模型的具体步骤：\n",
    "\n",
    "1. 导入库和模块\n",
    "\n",
    "2. 从 MNIST 加载图像数据\n",
    "\n",
    "3. 预处理图像数据\n",
    "\n",
    "4. 预处理分类标签\n",
    "\n",
    "5. 定义模型架构\n",
    "\n",
    "6. 编译模型\n",
    "\n",
    "7. 训练模型\n",
    "\n",
    "8. 评估模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 第一步：导入库和模块\n",
    "\n",
    "导入numpy。numpy可用于进行数组运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们从 `Keras` 中导入 `Sequential`，它是多个网络层的线性堆叠。\n",
    "\n",
    "简单来说，把 `Sequential` 想象成一个书架，每本书都是一个“网络层”，只要有了“书架”，你就可以把“书”一本本的堆叠上去。\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/%E4%B9%A6%E6%9E%B6-small.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之后，依次导入\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/%E5%90%84%E7%BD%91%E7%BB%9C%E5%B1%82.png)\n",
    "\n",
    "这些“网络层”，相当于上面书架中的“图书”。将这些“网络层”堆叠起来，就构成了文章开篇所提到的“最常见的CNNs架构”模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们从Keras导入 `np_utils`，它能帮助我们将数据形态转换为我们想要的样子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 第二步：从MNIST加载图像数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    " \n",
    "# 加载MNIST数据集，其中包含60,000个训练样本、10,000个测试样本\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "通过print，我们能够看到数据集的形态："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "# (60000, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "X_train是一个含有60,000个训练样本的数据集，并且，每一个样本图像的尺寸都是 $28*28$，例如，第1个训练样本为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfiBoAg/EBThB4Ii/EBQhB8IivADQf0/sEWOix6VKakAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f10e2df98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    " \n",
    "# 绘制第1个训练样本\n",
    "plt.imshow(X_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "看样子，上面的数字有可能是3，有可能是5。但是不管怎样，我们已经清楚地看到，X_train中的每一个样本，都是一张 $28*28$ 的手写数字图。\n",
    "\n",
    "接下来，我们再来看看y_train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "# (60000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "y_train是60,000个训练样本的标签，例如，第1个训练样本的标签为“5”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "# 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "好吧，原来上面那张歪歪扭扭的数字，不是3……\n",
    "\n",
    "使用同样的方法，我们还可以查看测试集的数据形态，在这里，我们有10,000个测试样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "# (10000, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**温馨提示：**\n",
    "\n",
    "无论是训练集，还是测试集，这里y的形态，都与X的不太一样\n",
    "\n",
    "例如，\n",
    "\n",
    "    X_train.shape=(60000, 28, 28)\n",
    "\n",
    "而 \n",
    "    \n",
    "    y_train.shape=(60000, )\n",
    "\n",
    "后面我们会将它们的形态进行调整，使它们保持一致，并符合图像识别的格式要求。\n",
    "\n",
    "### 2.3 第三步：预处理图像数据\n",
    "\n",
    "在CNNs中，图像不仅有“宽度”和“高度”，而且还有深度。\n",
    "\n",
    "对于彩色图片，图像的深度为3，即有“红R，绿G，蓝B”3个通道；\n",
    "\n",
    "对于像MNIST这样的灰度图片，其图像深度仅为1：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/%E5%9B%BE%E5%83%8F%E6%B7%B1%E5%BA%A6-small.jpg)\n",
    "\n",
    "所以，我们数据集的形态，应该从\n",
    "\n",
    " **<center>(样本数量, 图片宽度, 图片高度)</center>**\n",
    "\n",
    "转换为 \n",
    "\n",
    " **<center>(样本数量, <font color=\"red\">图片深度</font>, 图片宽度, 图片高度)</center>**\n",
    " \n",
    " 实现这一转换的方式很简单："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了确保我们的确已经将格式转换过来了，再次打印X_train.shape查看："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "# (60000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK，（样本数量,  图片深度, 图片宽度,  图片高度）我们已全都具备。\n",
    "预处理的最后一步，是将我们输入的数据，转换为float32类型，并且，将数值范围从[0, 255]标准化到[0, 1]范围内："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 第四步：预处理分类标签\n",
    "\n",
    "在第二步的时候，我们已经提到了，分类标签y的数据形态，似乎与图像X的有些不同。\n",
    "\n",
    "实际上，我们有“0~9”一共十个不同的类标签。\n",
    "\n",
    "我们期待看到这样的格式：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F.png)\n",
    "\n",
    "以此类推……\n",
    "\n",
    "但是，我们现在的y值，一上来就是 0,1,2, …… , 9。\n",
    "\n",
    "因此，我们需要对其进行转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换后的结果，我们来看一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "# (60000, 10)\n",
    " \n",
    "print(Y_train[0])\n",
    "# [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还记得我们将X_train形态转换后，得到的样子吗？\n",
    "\n",
    "X_train.shape=(60000, 1, 28, 28)\n",
    "\n",
    "表示“有60,000个样本，每个样本的维度为（$1*28*28$）”\n",
    "\n",
    "这里，经过转换后的Y_train的形态为\n",
    "\n",
    "Y_train.shape=(60000, 10)\n",
    "\n",
    "表示“有60,000个样本，每个样本的维度为10”\n",
    "\n",
    "**请记住上面的数据形态，只有当我们输入数据（X，Y）符合上述形态时，代码才会正常运行。**\n",
    "\n",
    "### 2.5 第五步：定义模型架构\n",
    "\n",
    "经过前四步，我们已经把所有的准备工作都做好了。现在，我们开始定义模型。\n",
    "\n",
    "回忆我们在开篇提到的“CNNs架构”\n",
    "\n",
    "再次祭上这张神图……\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/CNNs%E6%9E%B6%E6%9E%84.png)\n",
    "\n",
    "“定义模型架构”，意味着我们要确定图中“若干次”的具体次数。\n",
    "\n",
    "在本例中，我们将使用这样的架构：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/5-0%E6%8D%A2.png)\n",
    "\n",
    "当然，“若干次”的具体次数该如何来设定，并没有硬性的规定。\n",
    "\n",
    "你可以尝试构建不同的模式，并从中选择一个预测准确度最高的模型来使用。\n",
    "\n",
    "我们在这里使用了“2次 – 1次 – 2次”的结构。\n",
    "\n",
    "好啦，废话不多说，直接上代码。\n",
    "\n",
    "先搭一个“书架”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再往“model”中，添加各层。\n",
    "\n",
    "添加第1个“卷积 → ReLU”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加第一个卷积层，其中，超参数32,3,3分别表示“过滤器的个数、过滤器的宽、过滤器的高”\n",
    "# input_shape = (1, 28, 28)表示“输入图片的深度为1，宽度为28，高度为28”\n",
    "# model.add(Convolution2D(32, 3, 3, input_shape=(1, 28, 28)))\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    "\n",
    "# 添加激活层（ReLU）\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过滤器的作用是提取图片的特征，通常情况下，过滤器的个数由你自己来决定，这里设置了32个过滤器。\n",
    "\n",
    "过滤器的大小，你可以设置为 $3*3$，也可以设置为 $5*5$，都是较为常用的尺寸。\n",
    "\n",
    "经过第1个“卷积 → ReLU”的处理，我们来看看得到了什么："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 26, 26, 32)\n"
     ]
    }
   ],
   "source": [
    "print(model.output_shape)\n",
    "# (None, 32, 26, 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出的结果是，大小为 $26*26$，一共 $32$ 张图片。\n",
    "\n",
    "> 为什么是32张图片？\n",
    "\n",
    "> 这32张图片长得什么样子？\n",
    "\n",
    "> 为什么图片尺寸比输入时变小了？\n",
    "\n",
    "> 想要了解具体原理的同学，可以参考下面两篇教程：\n",
    "\n",
    "> [《吊炸天的CNNs，这是我见过最详尽的图解！（上）》](http://www.aiportal.net/cnns/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B-%E6%BB%A4%E6%B3%A2%E5%99%A8-%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81)\n",
    "\n",
    "> [《吊炸天的CNNs，这是我见过最详尽的图解！（下）》](http://www.aiportal.net/cnns/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B-%E6%B1%A0%E5%8C%96-%E5%85%A8%E8%BF%9E%E6%8E%A5-%E5%BD%A9%E8%89%B2%E5%9B%BE%E7%89%87%E5%8D%B7%E7%A7%AF)\n",
    "\n",
    "接下来，我们再添加第2个“卷积 → ReLU”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加第二个卷积层\n",
    "# 除第1层卷积外，其余各层卷积均不再需要输入input_shape，算法会自动识别其形态\n",
    "# model.add(Convolution2D(32,  3,  3))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    " \n",
    "# 添加激活层（ReLU）\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后是“池化层”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加池化层\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "池化层的作用是将图片缩小。\n",
    "\n",
    "**举个例子：**\n",
    "\n",
    "经过上面第2个“卷积 → ReLU”的处理后，输出结果的形态为\n",
    "\n",
    "（None, 32, 24, 24）\n",
    "\n",
    "表示“有 $32$ 张 $24*24$ 大小的图片”。\n",
    "\n",
    "经过“最大池化”的处理后，得到的是\n",
    "\n",
    "（None, 32, 12, 12）\n",
    "\n",
    "表示“有 $32$ 张 $12*12$ 大小的图片”，\n",
    "\n",
    "可以看到，图片的宽、高都缩小了一半。\n",
    "\n",
    "最后，我们来添加2个全连接层："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加展开层，因为，在“全连接层”之前，需要先将图片的像素值展开\n",
    "model.add(Flatten())\n",
    " \n",
    "# 添加第1个全连接层\n",
    "# “128”表示神经元的个数，可以设置为任意数值\n",
    "model.add(Dense(128, activation='relu'))\n",
    " \n",
    "# 添加dropout层，防止过拟合\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "# 添加第2个全连接层\n",
    "# “10”表示神经元的个数，但是由于本层为CNNs架构的最后一层（即“输出层”），\n",
    "# 所以，此处的数值只能为“10”，对应“0-9”个数字分类\n",
    "# “softmax”是非线性函数，输出的结果为“最初输入的图片，属于每种类别的概率”\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2.6 第六步：编译模型\n",
    "\n",
    "刚刚的第五步，我们只是搭起了一个模型的架子，而现在我们需要做的工作是，让模型能够跑起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 编译模型\n",
    "# 告诉模型，我们的目标是要使得“误差损失：categorical_crossentropy”尽可能小\n",
    "# 为了实现这一“目标”，所使用的优化方法是：adam\n",
    "# 使用“准确率：accuracy”来评估模型的预测效果\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 第七步：训练模型\n",
    "\n",
    "好啦，构建CNNs，所有最难的部分都已经过去了。\n",
    "\n",
    "下面，我们就要把数据 “喂给” 模型，让它开始为我们干活儿了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 55s - loss: 0.9991 - acc: 0.6678 - val_loss: 0.3502 - val_acc: 0.8981\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 56s - loss: 0.4919 - acc: 0.8477 - val_loss: 0.2725 - val_acc: 0.9171\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 57s - loss: 0.4343 - acc: 0.8657 - val_loss: 0.2479 - val_acc: 0.9289\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 58s - loss: 0.4040 - acc: 0.8760 - val_loss: 0.2240 - val_acc: 0.9342\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 60s - loss: 0.3827 - acc: 0.8827 - val_loss: 0.2097 - val_acc: 0.9381\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 60s - loss: 0.3629 - acc: 0.8871 - val_loss: 0.2053 - val_acc: 0.9383\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 60s - loss: 0.3501 - acc: 0.8897 - val_loss: 0.1888 - val_acc: 0.9439\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 60s - loss: 0.3457 - acc: 0.8932 - val_loss: 0.1867 - val_acc: 0.9442\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 61s - loss: 0.3289 - acc: 0.8998 - val_loss: 0.1867 - val_acc: 0.9439\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 62s - loss: 0.3224 - acc: 0.9008 - val_loss: 0.1792 - val_acc: 0.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6eda9ace10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "# batch_size=32 表示一批处理32个样本\n",
    "# nb_epoch=10 表示10个周期，每个周期都把全部60,000个样本遍历一遍\n",
    "# validation_split=0.3 表示从训练样本中拿出30%作为交叉验证集\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你的屏幕会显示这么一大堆东西：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/7-2.jpg)\n",
    "\n",
    "[原图](http://www.aiportal.net/wp-content/uploads/2017/12/7-2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 第八步：评估模型\n",
    "\n",
    "还记得我们在最初加载MNIST数据时，其中含有10,000个测试样本吗？\n",
    "\n",
    "在代码的最后，我们可以充分利用这10,000个测试样本，来评估我们构建的模型其预测效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s[0.16824836071655155, 0.94750000000000001]\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "score = model.evaluate(X_test,  Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "输出结果为：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/8-2.jpg)\n",
    "\n",
    "预测准确度高达0.989。\n",
    "\n",
    "**下面附上全部代码：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 59s - loss: 0.2395 - acc: 0.9264 - val_loss: 0.0717 - val_acc: 0.9764\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 60s - loss: 0.0897 - acc: 0.9725 - val_loss: 0.0503 - val_acc: 0.9852\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 62s - loss: 0.0671 - acc: 0.9799 - val_loss: 0.0480 - val_acc: 0.9852\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 63s - loss: 0.0524 - acc: 0.9835 - val_loss: 0.0383 - val_acc: 0.9886\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 63s - loss: 0.0439 - acc: 0.9865 - val_loss: 0.0406 - val_acc: 0.9876\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 61s - loss: 0.0349 - acc: 0.9886 - val_loss: 0.0445 - val_acc: 0.9874\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 63s - loss: 0.0315 - acc: 0.9899 - val_loss: 0.0383 - val_acc: 0.9898\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 63s - loss: 0.0285 - acc: 0.9906 - val_loss: 0.0394 - val_acc: 0.9898\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 61s - loss: 0.0222 - acc: 0.9927 - val_loss: 0.0438 - val_acc: 0.9899\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 63s - loss: 0.0237 - acc: 0.9922 - val_loss: 0.0393 - val_acc: 0.9903\n",
      " 9920/10000 [============================>.] - ETA: 0s[0.034495229029465099, 0.99119999999999997]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "# from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    " \n",
    "# 加载MNIST数据集，其中包含60,000个训练样本、10,000个测试样本\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    " \n",
    "# 调整加载数据的形态\n",
    "# X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "# X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    " \n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    " \n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    " \n",
    "model = Sequential()\n",
    " \n",
    "# 添加第一个卷积层，其中，超参数32,3,3分别表示“过滤器的个数、过滤器的宽、过滤器的高”\n",
    "# input_shape = (1, 28, 28)表示“输入图片的深度为1，宽度为28，高度为28”\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1)))\n",
    " \n",
    "# 添加激活层（ReLU）\n",
    "model.add(Activation('relu'))\n",
    " \n",
    "# 添加第二个卷积层\n",
    "# 除第1层卷积外，其余各层卷积均不再需要输入input_shape，算法会自动识别其形态\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    " \n",
    "# 添加激活层（ReLU）\n",
    "model.add(Activation('relu'))\n",
    " \n",
    "# 添加池化层\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "# 添加展开层，因为，在“全连接层”之前，需要先将图片的像素值展开\n",
    "model.add(Flatten())\n",
    " \n",
    "# 添加第1个全连接层\n",
    "# “128”表示神经元的个数，可以设置为任意数值\n",
    "model.add(Dense(128, activation='relu'))\n",
    " \n",
    "# 添加dropout层，防止过拟合\n",
    "model.add(Dropout(0.5))\n",
    " \n",
    "# 添加第2个全连接层\n",
    "# “10”表示神经元的个数，但是由于本层为CNNs架构的最后一层（即“输出层”），\n",
    "# 所以，此处的数值只能为“10”，对应“0-9”个数字分类\n",
    "# “softmax”是非线性函数，输出的结果为“最初输入的图片，属于每种类别的概率”\n",
    "model.add(Dense(10, activation='softmax'))\n",
    " \n",
    " \n",
    "# 编译模型\n",
    "# 告诉模型，我们的目标是要使得“误差损失：categorical_crossentropy”尽可能小\n",
    "# 为了实现这一“目标”，所使用的优化方法是：adam\n",
    "# 使用“准确率：accuracy”来评估模型的预测效果\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "# 训练模型\n",
    "# batch_size=32 表示一批处理32个样本\n",
    "# nb_epoch=10 表示10个周期，每个周期都把全部60,000个样本遍历一遍\n",
    "# validation_split=0.3 表示从训练样本中拿出30%作为交叉验证集\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=10, validation_split=0.3)\n",
    " \n",
    "# 评估模型\n",
    "score = model.evaluate(X_test,  Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[keras教程：卷积神经网络（CNNs）终极入门指南](http://www.aiportal.net/cnns/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-keras%E4%BB%A3%E7%A0%81)\n",
    "\n",
    "[关于Keras 2.0版本运行demo出错的问题](https://blog.csdn.net/JohinieLi/article/details/69222956)\n",
    "\n",
    "[Negative dimension size caused by subtracting 3 from 1 for 'conv2d_2/convolution'](https://stackoverflow.com/questions/45645276/negative-dimension-size-caused-by-subtracting-3-from-1-for-conv2d-2-convolution/45647715#45647715)\n",
    "\n",
    "[Keras 快速上手指南（中）：模型与网络层](http://xiaosheng.me/2017/07/05/article78/)\n",
    "\n",
    "[Keras:基于Python的深度学习库](http://keras-cn.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Sample CNN](../images/sample_cnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
