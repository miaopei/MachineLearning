{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP, TN, FP, FN的定义**\n",
    "\n",
    "在二分类问题中。\n",
    "\n",
    "|Real=1\t| Real=0 |\n",
    "| --- | --- |\n",
    "|Predict=1 | TP |\n",
    "|Predict=0 | FN |\n",
    "\n",
    "* TP: 预测为1(Positive)，实际也为1(Truth-预测对了)\n",
    "* TN: 预测为0(Negative)，实际也为0(Truth-预测对了)\n",
    "* FP: 预测为1(Positive)，实际为0(False-预测错了)\n",
    "* FN: 预测为0(Negative)，实际为1(False-预测错了)\n",
    "\n",
    "总的样本个数为：TP+TN+FP+FN。\n",
    "\n",
    "**Accuracy/Precision/Recall的定义**\n",
    "\n",
    "> Accuracy = (预测正确的样本数)/(总样本数)=(TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "> Precision = (预测为1且正确预测的样本数)/(所有预测为1的样本数) = TP/(TP+FP)\n",
    "\n",
    "> Recall = (预测为1且正确预测的样本数)/(所有真实情况为1的样本数) = TP/(TP+FN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[8种常见机器学习算法比较 - 偏差方差总结不错的连接](https://juejin.im/entry/58f482470ce463006bbaff8d)\n",
    "\n",
    "[机器学习算法汇总及选择](https://zhuanlan.zhihu.com/p/31711537)\n",
    "\n",
    "[如何选择机器学习算法](https://docs.microsoft.com/zh-cn/azure/machine-learning/studio/algorithm-choice)\n",
    "\n",
    "[在实际项目中，如何选择合适的机器学习模型？](http://gitbook.cn/books/5a37ef87b41c8814671a20e6/index.html)\n",
    "\n",
    "[机器学习”小憩“——总结应用场景](https://www.cnblogs.com/nolonely/p/6678256.html)\n",
    "\n",
    "[30分钟学会用scikit-learn的基本分类方法（决策树、SVM、KNN）和集成方法（随机森林，Adaboost和GBRT）](http://blog.csdn.net/u010900574/article/details/52669072)\n",
    "\n",
    "[30分钟学会用scikit-learn的基本回归方法（线性、决策树、SVM、KNN）和集成方法（随机森林，Adaboost和GBRT）](http://blog.csdn.net/u010900574/article/details/52666291)\n",
    "\n",
    "[机器学习实战](http://ml.apachecn.org/mlia/ensemble-random-tree-adaboost/)\n",
    "\n",
    "[随机森林的优缺点](http://blog.csdn.net/keepreder/article/details/47273297)\n",
    "\n",
    "[随机之美——机器学习中的随机森林模型](http://www.afenxi.com/post/13421)\n",
    "\n",
    "[优达（Udacity）finding_donors](http://blog.csdn.net/grape875499765/article/details/78773781)\n",
    "\n",
    "[kNN算法的优缺点](http://blog.csdn.net/ch1209498273/article/details/78440276)\n",
    "\n",
    "[各种机器学习的应用场景分别是什么？例如，k近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。](https://www.zhihu.com/question/26726794)\n",
    "\n",
    "[各常用分类算法的优缺点总结:DT/ANN/KNN/SVM/GA/Bayes/Adaboosting/Rocchio](http://blog.csdn.net/u014563989/article/details/43797977)\n",
    "\n",
    "[机器学习算法优缺点及其应用领域](http://blog.csdn.net/mach_learn/article/details/39501849)\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
