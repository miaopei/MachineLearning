{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tqdm \n",
    "\n",
    "`tqmd` 是一个快速，可扩展的 `Python` 进度条，可以在 `Python` 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 `tqdm(iterator)`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:44<00:00, 95.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "from tqdm import tqdm \n",
    "import time\n",
    "for i in tqdm(range(10000)):  \n",
    "    time.sleep(0.01)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. numpy.expand_dims的用法\n",
    "\n",
    "函数通过在指定位置插入新的轴来扩展数组形状。\n",
    "\n",
    "`expand_dims(a, axis)` 就是在 `axis` 的那一个轴上把数据加上去，这个数据在 `axis` 这个轴的 `0` 位置。 \n",
    "\n",
    "例如原本为一维的 `2` 个数据，`axis=0`，则 `shape` 变为 `(1,2)`,`axis=1` 则 `shape` 变为 `(2,1)` \n",
    "\n",
    "再例如 原本为 `(2,3)`,`axis=0`，则 `shape` 变为 `(1,2,3)`,`axis=1` 则 `shape` 变为`(2,1,3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1,2])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.expand_dims(x, axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numpy中stack()，hstack()，vstack()函数详解\n",
    "\n",
    "### 3.1 stack()函数 \n",
    "\n",
    "函数原型为：`stack(arrays, axis=0)`，`arrays` 可以传数组和列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "列表a如下：\n",
      "[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n",
      "增加一维，新维度的下标为0\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "增加一维，新维度的下标为1\n",
      "[[ 1  5  9]\n",
      " [ 2  6 10]\n",
      " [ 3  7 11]\n",
      " [ 4  8 12]]\n"
     ]
    }
   ],
   "source": [
    "a=[[1,2,3,4],\n",
    "   [5,6,7,8],\n",
    "   [9,10,11,12]]\n",
    "\n",
    "print(\"列表a如下：\")\n",
    "print(a)\n",
    "\n",
    "print(\"增加一维，新维度的下标为0\")\n",
    "c=np.stack(a,axis=0)\n",
    "print(c)\n",
    "\n",
    "print(\"增加一维，新维度的下标为1\")\n",
    "c=np.stack(a,axis=1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 hstack()函数 \n",
    "\n",
    "函数原型：`hstack(tup)` ，参数 `tup` 可以是元组，列表，或者 `numpy` 数组，返回结果为 `numpy` 的数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "b=[4,5,6]\n",
    "print(np.hstack((a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [2 2 2 2]\n",
      " [3 3 3 3]]\n"
     ]
    }
   ],
   "source": [
    "a=[[1],[2],[3]]\n",
    "b=[[1],[2],[3]]\n",
    "c=[[1],[2],[3]]\n",
    "d=[[1],[2],[3]]\n",
    "print(np.hstack((a,b,c,d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它其实就是水平(按列顺序)把数组给堆叠起来，`vstack()` 函数正好和它相反。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 vstack()函数 \n",
    "\n",
    "函数原型：`vstack(tup)` ，参数 `tup` 可以是元组，列表，或者 `numpy` 数组，返回结果为 `numpy` 的数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3]\n",
    "b=[4,5,6]\n",
    "print(np.vstack((a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [1]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "a=[[1],[2],[3]]\n",
    "b=[[1],[2],[3]]\n",
    "c=[[1],[2],[3]]\n",
    "d=[[1],[2],[3]]\n",
    "print(np.vstack((a,b,c,d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它是垂直（按照行顺序）的把数组给堆叠起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CNNs\n",
    "\n",
    "* 经过“卷积”层的处理后，图像含有深度，这个“深度”，等于过滤器的个数。\n",
    "\n",
    "* 如何确定“补零”的圈数，才能保证图片大小一致？\n",
    "\n",
    "    假设过滤器的大小为 F，滑动步幅 S=1，想要实现这一目标，补零的圈数为：\n",
    "$$P = \\frac{F - 1}{2}$$\n",
    "\n",
    "* 特征图片大小：\n",
    "\n",
    "    假设原始图片的大小为 W，过滤器的大小（F）、滑动的步幅（S）以及补零的圈数（P）：\n",
    "\n",
    "$$\\frac{W - F + 2 x P}{S}$$\n",
    "\n",
    "    所以，当我们设置这些超参数时，需要遵循一个原则，即“上面公式得到的结果，必须为一个整数”：\n",
    "\n",
    "![](http://aiportal.net/wp-content/uploads/2017/12/33%E5%85%AC%E5%BC%8F%E5%AE%88%E5%88%99.png)\n",
    "\n",
    "* 在提取特征的过程中，我们采用的是“过滤器中的数值，与原始图片中的相应数值，相乘、相加”的方法，例如：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/16ReLU-01-1.jpg)\n",
    "\n",
    "    事实上，在“卷积”过程中\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/34%E5%8D%B7%E7%A7%AF%E5%85%AC%E5%BC%8F.png)\n",
    "\n",
    "    上面这种对应数值相乘、再相加的计算，仅仅是“线性”计算；\n",
    "    而在现实世界中，很多很多的数据，都是“非线性”的。\n",
    "    所以，在“卷积”处理的后面，我们常常引入一个“非线性”的计算，来使得数据更加接近真实世界。\n",
    "    这个“非线性”计算，就是ReLU函数，它的图像形态犹如一条折线：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/35ReLU-02.jpg)\n",
    "\n",
    "    它就像是一个魔法袋子，所有经过它的数值：\n",
    "        \n",
    "        1. 如果是负数，出来的结果就是0\n",
    "        2. 如果是正数或零，出来的结果仍是自己本身\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/36%E9%AD%94%E6%B3%95%E8%A2%8B.png)\n",
    "\n",
    "    ReLU计算，相当于把一条直线（“线性”）掰弯。\n",
    "\n",
    "    虽然，这种方法有点儿简单（……粗暴），但是，它能使我们最终的预测准确度得到提升。\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/37%E6%8A%98%E5%BC%AF.png)\n",
    "\n",
    "    具体到图片计算，ReLU相当于将“特征图片”中，像素值小于0的部分，全部变为0。\n",
    "    \n",
    "    回到我们之前的例子中，在“卷积”的后面，再加上一步“ReLU计算”，即为：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/39%E6%9E%B6%E6%9E%841.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 所谓“池化”，就是在保留图片主要信息的前提下，将图片的尺寸缩小。\n",
    "\n",
    "    池化的类型有很多种，诸如“最大池化”、“平均池化”、“求和池化”等等，它们的运算原理基本一致。\n",
    "\n",
    "    因为“最大池化”更为常用，所以我们重点介绍“最大池化”的运算过程。\n",
    "\n",
    "    假设经过ReLU处理后，我们得到的特征图片，如下图：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/40%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96-01.jpg)\n",
    "\n",
    "    在对特征图片进行“池化”处理时，与“卷积”类似，需要我们设置2个超参数：\n",
    "        1. 过滤器大小（F）和 滑动的步幅数（S）\n",
    "        \n",
    "    这里，假设我们设置 F=2，S=2，那么，“最大池化”为：\n",
    "        > 在每 2*2（即4个）像素区域内，保留像素值最大的那一个，其余3个像素值抛弃。\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/41%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E8%BF%90%E7%AE%97.png)\n",
    "\n",
    "    这样，经过“池化”处理，就将一个4*4大小的图片，缩小为2*2大小的图片了。\n",
    "\n",
    "    当然，在“池化”过程中，你也可以将超参数设置为F=3、S=2，只不过“F=2、S=2”更为常用。\n",
    "\n",
    "    回到我们之前的例子中，在“ReLU计算”的后面，再加上一步“最大池化”，即为：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/5%E6%AD%A5%E9%AA%A42-1.jpg)\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/42%E6%9E%B6%E6%9E%842-1.png)\n",
    "\n",
    "> &emsp;&emsp;**输入图片 → 卷积 → ReLU → 池化（可选） **\n",
    "\n",
    "    当然，你也可以不拘泥于此。有的时候，我们会进行多次卷积和池化，所以，更一般的形式：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/43-%E6%9E%84%E6%9E%B6-%E6%8D%A2.png)\n",
    "\n",
    "    1. 池化”层使用的过滤器，与“卷积”层使用的过滤器有所不同：\n",
    "        池化”层的过滤器，其内部没有数值,因为“池化”层的过滤器，其功能只是将图片缩小，故其内部没有参数。\n",
    "        \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/44%E5%8C%BA%E5%88%AB1.png)\n",
    "\n",
    "    2. 在“池化”层中，仅有1个过滤器；而在“卷积”层中，可以设置多个过滤器。\n",
    "        因为“卷积”层的过滤器，其功能是提取图片的特征，因而，我们使用不同的过滤器，可以提取不同的图片细节。\n",
    "\n",
    "        而“池化”层的过滤器，仅仅是为了缩小图片的尺寸，因而，使用一种过滤器，就可以达到这一目标，无需设置多个。\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/45%E5%8C%BA%E5%88%AB2.png)\n",
    "\n",
    "    3. 经过“卷积”处理后，得到的图片张数（即“图片深度”），应该等于该卷积层的过滤器个数；\n",
    "\n",
    "        而经过“池化”处理后，得到的图片张数（即“图片深度”），仍等于上一层的图片张数。\n",
    "\n",
    "        概念描述比较晦涩，直接看下图：\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/46%E5%8C%BA%E5%88%AB3.png)\n",
    "\n",
    "    当仅有1个卷积层时，关于每一层的图片深度问题，尚且好理解（如上图所示）。\n",
    "\n",
    "    但是，当模型中含有多个卷积层，或者，输入的图片为彩色图片时，这个问题就容易被混淆，后面，我们在讲到彩色图片的图像处理时，仍会强调这个问题，此处，仅需记住这一概念就可以。\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/6%E6%AD%A5%E9%AA%A43.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 最后一步，该轮到我们的压轴大戏——“图片分类”了。\n",
    "\n",
    "    经过上面一系列的处理，此时得到的图片，已经可以被视为一串串简单的数字（即像素值）。\n",
    "\n",
    "    将这一个个的像素值，塞到我们初中就已接触过的表达式中：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/47%E8%A1%A8%E8%BE%BE%E5%BC%8F.png)\n",
    "\n",
    "    1. x 是谁？\n",
    "\n",
    "        还记得之前讲的计算机“眼中”的世界吗？\n",
    "        \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/7dog-%E9%BB%91%E7%99%BD-%E5%83%8F%E7%B4%A0-1.jpg)\n",
    "\n",
    "    那一个格子、一个格子中的数字，就是 x。\n",
    "    \n",
    "    2. y 是谁？\n",
    "\n",
    "        我们给每张图片打上的标签：这张图是“猫”、那张图是“狗”…… 统统这些标签，就是 y。\n",
    "\n",
    "    3. θ 是什么鬼？\n",
    "\n",
    "        当你给计算机很多组、很多组（x,y）时，它会自己去学习寻找x与y之间的关系，这个“关系”，就是 θ。\n",
    "\n",
    "        当你拥有了 θ，下一次，即使拿到一张没有打过标签的图片，你也可以通过已知的 θ 和 x，知道y的取值，从而“知道图片里画的是什么？”。\n",
    "        \n",
    "* 所以，在“第3步 – 图片分类”中：\n",
    "\n",
    "    首先，需要把第2步得到的图片，其中的像素值“展开”。\n",
    "\n",
    "    为了方便大家理解，假设我们从第 2 步中，得到了 2 张 2*2 的图片，如果把它们的像素值“展开”，得到的效果为：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/48FC-07.jpg)\n",
    "\n",
    "    这样，我们就拿到了x。展开后所得到的 \n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/48-%E8%A1%A5.jpg)\n",
    "\n",
    "    就是 x。\n",
    "\n",
    "    在训练的最初，我们拥有每张图片的标签，即“我们已经拥有了y值”。\n",
    "\n",
    "    所以，在模型的最后，我们需要让计算机努力找到x-y之间的关系。\n",
    "\n",
    "    而寻找的办法，就需要依靠“全连接神经网络”：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/49FC.png)\n",
    "\n",
    "    所谓“全连接”，是指下一层的每一个神经元（即图中的“□”），与上一层的神经元全部相连，这里为了表达得更清晰，已经省去了中间的连接符。实际上，更多的时候，你会看到下面这样的图片：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/50FC-10.jpg)\n",
    "\n",
    "* 本文的核心在于卷积神经网络（CNNs）。\n",
    "\n",
    "    这里，你只需要记住2点：\n",
    "    \n",
    "    1. “全连接神经网络”可以帮助我们学习到参数 θ。有了它，下一次再给计算机“看”图片时，计算机便会自动识别出图中的景象。\n",
    "    \n",
    "    2. 模型得到的最终结果，表示“图片为某种类别的概率”。注意：这里的概率之和，永远为 1。\n",
    "    \n",
    "    例如：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/51FC%E7%BB%93%E6%9E%9C.png)\n",
    "\n",
    "    即计算机“判断”，最初输入的图片为“狗”。\n",
    "\n",
    "    我们将CNNs的所有流程，整合起来，即：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/52%E6%95%B4%E5%90%88%E5%9B%BE%EF%BC%88%E9%87%87%E7%94%A8%EF%BC%89.jpg)\n",
    "\n",
    "[**原图**](http://www.aiportal.net/wp-content/uploads/2017/12/52%E6%95%B4%E5%90%88%E5%9B%BE%EF%BC%88%E9%87%87%E7%94%A8%EF%BC%89.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/66%E5%BD%A9%E8%89%B2%E5%8D%B7%E7%A7%AF-%E5%8A%A8%E7%94%BB.gif)\n",
    "\n",
    "[**原图**](http://www.aiportal.net/wp-content/uploads/2017/12/66%E5%BD%A9%E8%89%B2%E5%8D%B7%E7%A7%AF-%E5%8A%A8%E7%94%BB.gif)\n",
    "\n",
    "* **总 结**\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/71%E8%AF%86%E5%88%AB%E5%9B%BE%E7%89%87%E8%BF%87%E7%A8%8B%E2%80%94%E2%80%94%E4%BA%BA%E6%9C%BA%E5%AF%B9%E6%AF%94.jpg)\n",
    "\n",
    "    用图片可以更形象的表述\n",
    "\n",
    "    人类：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/72%E6%80%BB%E7%BB%931.png)\n",
    "\n",
    "    计算机：\n",
    "    \n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/69%E7%AD%89%E4%BB%B7%E4%BA%8E.jpg)\n",
    "\n",
    "[**原图**](http://www.aiportal.net/wp-content/uploads/2017/12/69%E7%AD%89%E4%BB%B7%E4%BA%8E.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**在构建模型时，需要我们设置的超参数有：**\n",
    "\n",
    "* 卷积层： 过滤器的大小（F）、滑动的步幅数（S），以及过滤器的个数（K）\n",
    "    如果你期望输出的图片，与输入的图片尺寸一致，你还可以在原始图片的外围补零，补零的圈数 $P=\\frac{F - 1}{2}$\n",
    "    \n",
    "* 池化层：过滤器的大小（F）\n",
    "\n",
    "**在算法运行时，计算机会自己学习的参数有：**\n",
    "\n",
    "* 卷积层： 过滤器中的具体数值。\n",
    "\n",
    "![](http://www.aiportal.net/wp-content/uploads/2017/12/73%E6%80%BB%E7%BB%932.png)\n",
    "\n",
    "* 全连接层： 神经元的参数 θ\n",
    "\n",
    "    当计算机算出最优参数后，下一次，在输入一张没有打过标签的图片时，算法就能自动对图片做出分类。\n",
    "    \n",
    "**结束语**\n",
    "\n",
    "    卷积神经网络（CNNs）能够提取图像的核心特征，并使用这些特征，来识别包含类似特征的图像，在“自动驾驶”、“人类识别”、“医疗图像诊断”等方面，都发挥着极大的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 库和框架中文社区\n",
    "\n",
    "[Keras: 基于 Python 的深度学习库](https://keras.io/zh/)\n",
    "\n",
    "[Keras:基于Python的深度学习库](https://keras-cn.readthedocs.io/en/latest/)\n",
    "\n",
    "[OpenCV参考手册](http://wiki.opencv.org.cn/index.php/Template:Doc)\n",
    "\n",
    "[Tensorflow 中文社区](http://www.tensorfly.cn/tfdoc/get_started/os_setup.html)\n",
    "\n",
    "[Scikit-Learn CN](http://cwiki.apachecn.org/display/sklearn/Index)\n",
    "\n",
    "[scikit-learn Python 中的机器学习](http://sklearn.apachecn.org/cn/0.19.0/index.html)\n",
    "\n",
    "[机器学习资源](https://feisky.xyz/machine-learning/appendix/reference.html)\n",
    "\n",
    "[Numpy 教程](https://wizardforcel.gitbooks.io/ts-numpy-tut/content/12.html)\n",
    "\n",
    "[数学乐](https://www.shuxuele.com/index.html)\n",
    "\n",
    "[Theano 中文文档 0.9](https://www.ctolib.com/docs/sfile/theano-docs/index.html)\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference \n",
    "\n",
    "[Numpy中stack()，hstack()，vstack()函数详解](https://blog.csdn.net/csdn15698845876/article/details/73380803)\n",
    "\n",
    "[吊炸天的CNNs，这是我见过最详尽的图解！（上）](http://www.aiportal.net/cnns/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B-%E6%BB%A4%E6%B3%A2%E5%99%A8-%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81)\n",
    "\n",
    "[吊炸天的CNNs，这是我见过最详尽的图解！（下）](http://www.aiportal.net/cnns/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B-%E6%B1%A0%E5%8C%96-%E5%85%A8%E8%BF%9E%E6%8E%A5-%E5%BD%A9%E8%89%B2%E5%9B%BE%E7%89%87%E5%8D%B7%E7%A7%AF)\n",
    "\n",
    "[keras教程：卷积神经网络（CNNs）终极入门指南](http://www.aiportal.net/cnns/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB-keras%E4%BB%A3%E7%A0%81)\n",
    "\n",
    "[Cmd Markdown 公式指导手册](https://www.zybuluo.com/codeep/note/163962)\n",
    "\n",
    "[卷积神经网络改进想法初探（上篇）](https://blog.csdn.net/u010402786/article/details/49272757)\n",
    "\n",
    "[CNN卷积神经网络的改进（15年最新paper）](https://blog.csdn.net/u010402786/article/details/50499864)\n",
    "\n",
    "[Deep Visualization:可视化并理解CNN](https://zhuanlan.zhihu.com/p/24833574)\n",
    "\n",
    "[CNN超参数优化和可视化技巧详解](https://zhuanlan.zhihu.com/p/27905191)\n",
    "\n",
    "[如何一步一步提高图像分类准确率？](https://www.leiphone.com/news/201709/NByqFlpeg3DcQQ7A.html)\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()\n",
    "\n",
    "[]()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
